{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bb279c-800c-409c-b0cc-279dd82c7ad6",
   "metadata": {},
   "source": [
    "## Load documents with IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8f2b31-7953-4ebc-a98e-fa4a35454cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd6692d-7d39-40b1-85c1-e1a7be36a114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'ea739c65'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b993b29-1aa3-44a3-ad50-1492abca6137",
   "metadata": {},
   "source": [
    "## Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cdd9da-6179-4211-b82c-6047276f27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df0fb88-e479-4fd5-a83d-9f4fbeca6b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2082291-7d2b-4b9d-9c4b-0b7e0327c785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything is recorded, so you wonâ€™t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx = {d['id']: d for d in documents}\n",
    "doc_idx['5170565b']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117de4a5-e7fc-4a9c-af1e-6c742d00c7f7",
   "metadata": {},
   "source": [
    "## Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b692f3-b3c7-4d0f-9857-4b6fa0a5f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30ee16f-ceaa-40ae-b706-b69268fc2fcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7cd0509a9c00>: Failed to establish a new connection: [Errno 111] Connection refused))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m      5\u001b[0m index_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_shards\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     }\n\u001b[1;32m     25\u001b[0m }\n\u001b[1;32m     27\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcourse-questions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mes_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_unavailable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m es_client\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mcreate(index\u001b[38;5;241m=\u001b[39mindex_name, body\u001b[38;5;241m=\u001b[39mindex_settings)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elasticsearch/_sync/client/indices.py:736\u001b[0m, in \u001b[0;36mIndicesClient.delete\u001b[0;34m(self, index, allow_no_indices, error_trace, expand_wildcards, filter_path, human, ignore_unavailable, master_timeout, pretty, timeout)\u001b[0m\n\u001b[1;32m    734\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m timeout\n\u001b[1;32m    735\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDELETE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindices.delete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:423\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    412\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:316\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 316\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    338\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elastic_transport/_transport.py:342\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta, otel_span)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     otel_span\u001b[38;5;241m.\u001b[39mset_node_metadata(node\u001b[38;5;241m.\u001b[39mhost, node\u001b[38;5;241m.\u001b[39mport, node\u001b[38;5;241m.\u001b[39mbase_url, target)\n\u001b[0;32m--> 342\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         )\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py:202\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e), errors\u001b[38;5;241m=\u001b[39m(e,))\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    196\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    197\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m         exception\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m meta \u001b[38;5;241m=\u001b[39m ApiResponseMeta(\n\u001b[1;32m    205\u001b[0m     node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    206\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresponse_headers,\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    212\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    213\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     response\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    218\u001b[0m )\n",
      "\u001b[0;31mConnectionError\u001b[0m: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7cd0509a9c00>: Failed to establish a new connection: [Errno 111] Connection refused))"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e65be-38be-4549-bdfc-c108f7d167d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    doc['question_text_vector'] = model.encode(question + ' ' + text)\n",
    "\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f0571-b946-408a-8d94-81b703596b71",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc227ef3-227d-4a1e-a526-348a8d48edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0451e-78b6-43af-839d-e8eb95deea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text_vector_knn(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230717e3-de51-43a3-a014-140d7eb04b1c",
   "metadata": {},
   "source": [
    "## The RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225ae18-dede-44c9-9e25-2e0121478be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27275b63-f5c3-495a-85f0-37715db0a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058df3b4-617c-49a1-85e4-697c12429173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict, model='gpt-4o') -> str:\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de987c0d-9c66-478b-ba26-ed5e7b6f8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b562b49-c0e2-4e1c-b899-65e9fcb6ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72a787-3efd-4423-b5e2-29568ce97972",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx['5170565b']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f384c-ae67-468e-ab74-0aac56b59b92",
   "metadata": {},
   "source": [
    "## Cosine similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899efef-1d16-47f6-a6ad-39d9ec9f88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_orig = 'Yes, sessions are recorded if you miss one. Everything is recorded, allowing you to catch up on any missed content. Additionally, you can ask questions in advance for office hours and have them addressed during the live stream. You can also ask questions in Slack.'\n",
    "answer_llm = 'Everything is recorded, so you wonâ€™t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'\n",
    "\n",
    "v_llm = model.encode(answer_llm)\n",
    "v_orig = model.encode(answer_orig)\n",
    "\n",
    "v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45986c16-25d4-46c7-9947-d5492166b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54007f6f-4a3f-4580-a991-46483e2fc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f95c-6a6e-469a-ba26-e2514120fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ef467-0db5-40eb-bd27-0f6eebb1bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d709d0-dac6-403b-936a-e09ad0c53860",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rec in enumerate(tqdm(ground_truth)):\n",
    "    if i in answers:\n",
    "        continue\n",
    "\n",
    "    answer_llm = rag(rec)\n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c266f8-e791-4620-a6ca-f21fbce1f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4o = [None] * len(ground_truth)\n",
    "\n",
    "for i, val in answers.items():\n",
    "    results_gpt4o[i] = val.copy()\n",
    "    results_gpt4o[i].update(ground_truth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072378d5-9206-42a3-b957-7a21b101284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd1cfc-ccf7-4ab2-ac38-d6b2d65e7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o = pd.DataFrame(results_gpt4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46c9a5-5e70-4a3d-bca0-166908c11660",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9169fb8-725b-470c-8b95-ea6a3620d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o.to_csv('data/results-gpt4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2600f-161b-4ca8-a2e9-75ad344eef1a",
   "metadata": {},
   "source": [
    "## Evaluating GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa011422-3785-4f8b-a889-c825847cfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(ground_truth[10], model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d2b02-ed3d-43ac-a4fb-28438f338fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f4b5a-f7cd-42ac-888c-57573826473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(rec):\n",
    "    model = 'gpt-3.5-turbo'\n",
    "    answer_llm = rag(rec, model=model)\n",
    "    \n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9ff05-040b-4163-ad31-6e7b1d46db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_record(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a0ece-8fa3-4b27-ad57-67016ac0434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt35 = map_progress(pool, ground_truth, process_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f9832-2c55-4cff-aaee-763d3d6a1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt35 = pd.DataFrame(results_gpt35)\n",
    "df_gpt35.to_csv('data/results-gpt35.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6a261-69b8-43e4-81be-16fda877d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/results-gpt35.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadff8cd-b0a3-4d9c-b9fb-5e1214c0b151",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "A -> Q ->A' cosine similarity\n",
    "\n",
    "cosine(A, A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a13ef35-063b-4e74-a627-205fd904781e",
   "metadata": {},
   "source": [
    "### gpt 4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3404971-a1ea-4ce1-a0b5-6b9621b851ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4o = df_gpt4o.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62450c4-ce4d-4b8e-9dda-b183b24e7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = results_gpt4o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474f28c-a920-4296-9366-42fa1ee9418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_orig = model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12f6ea-a2e9-402a-bed8-e0a47d510f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "\n",
    "for record in tqdm(results_gpt4o):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55d332-4326-44d9-8b38-18eb53ee70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o['cosine'] = similarity\n",
    "df_gpt4o['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5ddb4-082f-40cc-9c68-9f994ae64be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ce3d3-79ff-43e8-bdf7-5a77db74bee4",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28628c80-7520-4050-8c4b-6170e690dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt35 = df_gpt35.to_dict(orient='records')\n",
    "\n",
    "similarity_35 = []\n",
    "\n",
    "for record in tqdm(results_gpt35):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity_35.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6b5cb-c557-4ce5-a62b-e8c3d47d8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt35['cosine'] = similarity_35\n",
    "df_gpt35['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35748fc7-ef82-4633-9a1b-b464cace6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3a5eb-d827-470b-8910-1ae9868acf44",
   "metadata": {},
   "source": [
    "### gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ab1d6-b18e-4fd8-baac-aa18d0ce1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record_4o_mini(rec):\n",
    "    model = 'gpt-4o-mini'\n",
    "    answer_llm = rag(rec, model=model)\n",
    "    \n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7f0dd-135a-4cb5-b8bc-cd5f89aeec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_record_4o_mini(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e580e78-6470-4542-a0f7-2f477cce2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4omini = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213cb391-2eb7-444f-b554-6080e13bd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tqdm(ground_truth):\n",
    "    result = process_record_4o_mini(record)\n",
    "    results_gpt4omini.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513e0fe-6459-413c-a319-d4416df8a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o_mini = pd.DataFrame(results_gpt4omini)\n",
    "df_gpt4o_mini.to_csv('data/results-gpt4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead63a8-21dd-481a-a559-e4a16d62a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_4o_mini = []\n",
    "\n",
    "for record in tqdm(results_gpt4omini):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity_4o_mini.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea65e8-255a-41c1-88d6-fc335f619d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o_mini['cosine'] = similarity_4o_mini\n",
    "df_gpt4o_mini['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13c445-a715-474f-b8df-223772d64a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_gpt35['cosine'], label='3.5')\n",
    "\n",
    "sns.distplot(df_gpt4o['cosine'], label='4o')\n",
    "sns.distplot(df_gpt4o_mini['cosine'], label='4o-mini')\n",
    "\n",
    "plt.title(\"RAG LLM performance\")\n",
    "plt.xlabel(\"A->Q->A' Cosine Similarity\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4dd3d-cfdd-44ac-b62b-2908ea91f565",
   "metadata": {},
   "source": [
    "## LLM-as-a-judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e55e25-3947-4136-af77-b158d0e9affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943e4a8-1843-4dce-97d5-a3ec0ac6e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_gpt4o_mini.sample(n=150, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa28b6-6933-44d1-8c05-986d2c641696",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1efda-68a4-4033-9a5b-6355135756ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = samples[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd20252-bd86-4693-82c5-52fc2ec81e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c01a01-fb24-4ebd-a2b8-3924a9f81c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014b8c2-411c-4af1-bae6-f557e4ec89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba3ab2-94b8-421a-ab76-650b5b806a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d73766-5a74-467a-a60f-b3b4896510c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f497d-0321-45d1-814e-707eaeb6ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations = pd.DataFrame(json_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb796566-ac9c-49a6-8b6a-b7c9cf5f1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd496e-95b9-4699-a81e-0d95aa3e75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations[df_evaluations.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32680925-f7ef-4c91-a34f-21f42c79b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c6d4e-1bfc-406a-99ae-f7e4e5cbe8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace65540-4ce2-4158-b31e-b6596c54cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb28e6-598d-4f13-b1f7-4e7b7ba3f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_2 = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt2_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_2.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75683c-e4bd-4d0c-a721-4dba0b81c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations_2 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_2):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations_2.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb9e96-9375-4614-a28e-13c803bf314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2 = pd.DataFrame(json_evaluations_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1ede7-6d23-446b-b192-b2717616d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2[df_evaluations_2.Relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8856dc7-6f67-499f-ae57-04c13aec7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a7049-8f91-48f6-afd6-d51d0a82cb24",
   "metadata": {},
   "source": [
    "## Saving all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7e377-7c7e-485c-80fb-e01706f8055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o.to_csv('data/results-gpt4o-cosine.csv', index=False)\n",
    "df_gpt35.to_csv('data/results-gpt35-cosine.csv', index=False)\n",
    "df_gpt4o_mini.to_csv('data/results-gpt4o-mini-cosine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f67e6-56c0-454a-a196-dd2509b7d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.to_csv('data/evaluations-aqa.csv', index=False)\n",
    "df_evaluations_2.to_csv('data/evaluations-qa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bab1f6-4edd-4003-88cc-bd5f421b7d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c5b8c-3959-478e-b1b2-561bf60ba3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
